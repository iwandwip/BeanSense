# BeanSense: Coffee Classification System

BeanSense is a machine learning system designed to classify coffee samples based on sensor readings. It combines deep learning architectures for feature extraction with various classifiers to achieve accurate coffee bean identification and classification.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [System Architecture](#system-architecture)
- [Technology Stack](#technology-stack)
- [Installation](#installation)
- [Project Structure](#project-structure)
- [Usage](#usage)
- [Models](#models)
- [Datasets](#datasets)
- [Performance Metrics](#performance-metrics)

## âœ¨ Features

- **Multiple Classification Models**: Implements 7 different machine learning models for flexibility and performance
- **Deep Feature Extraction**: Uses pre-trained CNN architectures (MobileNet, ResNet) to extract meaningful features from raw sensor data
- **Client-Server Architecture**: Provides a distributed system for remote prediction and training
- **Autoencoder Dimensionality Reduction**: Employs autoencoders for feature compression
- **Feature Selection**: Incorporates ICCS (Improved Cuckoo Search) for optimal feature selection
- **Cross-Validation**: Implements stratified k-fold cross-validation for model evaluation
- **Hyperparameter Tuning**: Uses GridSearchCV for SVM model optimization
- **Real-time Classification**: Supports immediate prediction of coffee samples
- **Memory & Performance Tracking**: Measures execution time and memory usage for each operation

## ğŸ—ï¸ System Architecture

BeanSense employs a client-server architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚      â”‚                 â”‚      â”‚                   â”‚
â”‚ User Interface  â”‚<â”€â”€â”€â”€>â”‚ Server          â”‚<â”€â”€â”€â”€>â”‚ Client            â”‚
â”‚ (CLI)           â”‚      â”‚ (HTTP)          â”‚      â”‚ (ML Models)       â”‚
â”‚                 â”‚      â”‚                 â”‚      â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Server**: Handles requests, stores datasets, and delivers commands to the client
- **Client**: Executes the machine learning models, performs training and prediction
- **Wrapper**: Provides a unified interface to all classification models

## ğŸ”§ Technology Stack

- **Python 3.x**: Primary programming language
- **PyTorch**: Deep learning framework for feature extraction
- **scikit-learn**: Machine learning tools for model evaluation and preprocessing
- **LightGBM, CatBoost**: Gradient boosting frameworks
- **NumPy, Pandas**: Data manipulation and analysis
- **HTTP Server**: Simple HTTP interface for client-server communication

## ğŸ“¥ Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/yourusername/BeanSense.git
   cd BeanSense
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“ Project Structure

```
BeanSense/
â”œâ”€â”€ .backup/               # Backup files directory
â”œâ”€â”€ cache/                 # Cache directory for temporary files
â”œâ”€â”€ catboost_info/         # Information generated by CatBoost models
â”œâ”€â”€ datasets/              # Dataset files
â”‚   â”œâ”€â”€ origin/            # Original dataset files
â”‚   â”œâ”€â”€ dataset4.csv       # 4-sensor dataset
â”‚   â”œâ”€â”€ dataset6.csv       # 6-sensor dataset
â”‚   â””â”€â”€ dataset8.csv       # 8-sensor dataset
â”œâ”€â”€ model/                 # Trained model files
â”‚   â”œâ”€â”€ default_model/     # Default model files
â”‚   â”œâ”€â”€ adaboost_resnet_model_4.pkl     # AdaBoost + ResNet model (4 sensors)
â”‚   â”œâ”€â”€ adaboost_resnet_model_6.pkl     # AdaBoost + ResNet model (6 sensors)
â”‚   â”œâ”€â”€ adaboost_resnet_model_8.pkl     # AdaBoost + ResNet model (8 sensors)
â”‚   â”œâ”€â”€ autoencoder_lightgbm_model_4.pkl  # Autoencoder + LightGBM model (4 sensors)
â”‚   â”œâ”€â”€ autoencoder_lightgbm_model_6.pkl  # Autoencoder + LightGBM model (6 sensors)
â”‚   â”œâ”€â”€ autoencoder_lightgbm_model_8.pkl  # Autoencoder + LightGBM model (8 sensors)
â”‚   â”œâ”€â”€ catboost_resnet_model_4.pkl     # CatBoost + ResNet model (4 sensors)
â”‚   â”œâ”€â”€ catboost_resnet_model_6.pkl     # CatBoost + ResNet model (6 sensors)
â”‚   â”œâ”€â”€ catboost_resnet_model_8.pkl     # CatBoost + ResNet model (8 sensors)
â”‚   â”œâ”€â”€ lightgbm_resnet_model_4.pkl     # LightGBM + ResNet model (4 sensors)
â”‚   â”œâ”€â”€ lightgbm_resnet_model_6.pkl     # LightGBM + ResNet model (6 sensors)
â”‚   â”œâ”€â”€ lightgbm_resnet_model_8.pkl     # LightGBM + ResNet model (8 sensors)
â”‚   â”œâ”€â”€ mobilenet_iccs_lightgbm_model_4.pkl  # MobileNet + ICCS + LightGBM model (4 sensors)
â”‚   â”œâ”€â”€ mobilenet_iccs_lightgbm_model_6.pkl  # MobileNet + ICCS + LightGBM model (6 sensors)
â”‚   â”œâ”€â”€ mobilenet_iccs_lightgbm_model_8.pkl  # MobileNet + ICCS + LightGBM model (8 sensors)
â”‚   â”œâ”€â”€ mobilenet_lightgbm_model_4.pkl  # MobileNet + LightGBM model (4 sensors)
â”‚   â”œâ”€â”€ mobilenet_lightgbm_model_6.pkl  # MobileNet + LightGBM model (6 sensors)
â”‚   â”œâ”€â”€ mobilenet_lightgbm_model_8.pkl  # MobileNet + LightGBM model (8 sensors)
â”‚   â”œâ”€â”€ rbf_svm_gs_model_4.pkl          # RBF SVM + GridSearch model (4 sensors)
â”‚   â”œâ”€â”€ rbf_svm_gs_model_6.pkl          # RBF SVM + GridSearch model (6 sensors)
â”‚   â””â”€â”€ rbf_svm_gs_model_8.pkl          # RBF SVM + GridSearch model (8 sensors)
â”œâ”€â”€ utils/                 # Utility scripts and helpers
â”œâ”€â”€ venv/                  # Python virtual environment
â”œâ”€â”€ __pycache__/           # Python cache files
â”œâ”€â”€ .gitignore             # Git ignore file
â”œâ”€â”€ AdaBoostClassifier.py  # AdaBoost classifier implementation
â”œâ”€â”€ AutoencoderLightGBM.py # Autoencoder + LightGBM implementation
â”œâ”€â”€ CatBoostClassifier.py  # CatBoost classifier implementation
â”œâ”€â”€ ClassifierWrapper.py   # Unified interface for all classifiers
â”œâ”€â”€ CoffeeClassifierClient.py # Client implementation
â”œâ”€â”€ CoffeeClassifierServer.py # Server implementation
â”œâ”€â”€ LightGBMMobileNet.py   # LightGBM + MobileNet implementation
â”œâ”€â”€ LightGBMResNet.py      # LightGBM + ResNet implementation
â”œâ”€â”€ MobileNetICCSLightGBM.py # MobileNet + ICCS + LightGBM implementation
â”œâ”€â”€ RBFSVMGridSearch.py    # RBF SVM + GridSearch implementation
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ requirements.txt       # Python dependencies
```

## ğŸš€ Usage

### Server Setup

1. **Start the server**

   ```bash
   python CoffeeClassifierServer.py
   ```

2. **Select operations from the interactive menu:**
   - Train model
   - Make prediction
   - Check status
   - View latest result

### Client Operation

1. **Start the client (in a separate terminal)**

   ```bash
   python CoffeeClassifierClient.py
   ```

2. **Training a model**

   - Select "Train model" on the server
   - Choose dataset (4, 6, or 8 sensors)
   - Select model type
   - Monitor progress on the client

3. **Making predictions**
   - Select "Make prediction" on the server
   - Choose the dataset and model type
   - Enter sensor values (comma-separated)
   - View results

### Direct Model Usage

You can also use the models directly in your own code:

```python
from LightGBMMobileNet import MobileNetLightGBMModel

# Initialize model
model = MobileNetLightGBMModel()

# Load data
X, y = model.load_data("datasets/dataset4.csv")

# Train model
metrics = model.train(X, y)

# Make prediction
result = model.predict_single([123, 456, 789, 101])
print(f"Prediction: {result}")

# Save model
model.save_model("model/my_model.pkl")
```

## ğŸ§  Models

BeanSense includes seven distinct classification models:

1. **LightGBM + MobileNet**: Combines MobileNetV2 feature extraction with LightGBM classification
2. **LightGBM + ResNet**: Uses ResNet18 for feature extraction with LightGBM classification
3. **MobileNet + ICCS + LightGBM**: Adds feature selection using Improved Cuckoo Search algorithm
4. **AdaBoost + ResNet**: Combines ResNet18 features with AdaBoost ensemble learning
5. **Autoencoder + LightGBM**: Uses an autoencoder for dimensionality reduction before classification
6. **CatBoost + ResNet**: Utilizes CatBoost classifier with ResNet features
7. **RBF SVM + GridSearch**: Implements Support Vector Machines with grid search for hyperparameter tuning

Each model employs different strategies for feature extraction, selection, and classification to provide comprehensive analysis options.

## ğŸ“Š Datasets

The system works with three types of datasets based on the number of sensors:

1. **dataset4.csv**: 4 sensors (MQ135, MQ2, MQ3, MQ6)
2. **dataset6.csv**: 6 sensors (MQ135, MQ2, MQ3, MQ6, MQ138, MQ7)
3. **dataset8.csv**: 8 sensors (MQ135, MQ2, MQ3, MQ6, MQ138, MQ7, MQ136, MQ5)

The datasets classify coffee samples with labels like:

- aKaw-D, aKaw-M, aKaw-L (Arabica Kawisari - Dark/Medium/Light roast)
- aSem-D, aSem-M, aSem-L (Arabica Semeru - Dark/Medium/Light roast)
- rGed-D, rGed-M, rGed-L (Robusta Gedung - Dark/Medium/Light roast)
- rTir-D, rTir-M, rTir-L (Robusta Tirtoyudo - Dark/Medium/Light roast)

## ğŸ“ˆ Performance Metrics

The system evaluates models using multiple metrics:

- **Accuracy**: Overall prediction accuracy
- **F1-Score**: Harmonic mean of precision and recall
- **AUC**: Area Under the ROC Curve
- **Memory Usage**: Peak memory consumption during operation
- **Execution Time**: Time taken for training and prediction

Each model outputs these metrics during training, allowing for direct comparison.

---

Created by:

- **Iwan Dwi**: [iwan.dwp@gmail.com]
- **Ahmad Zainul**: [ahmadzainularifin6@gmail.com]
